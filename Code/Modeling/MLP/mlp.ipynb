{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T08:10:55.723524606Z",
     "start_time": "2023-09-30T08:10:55.624038137Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T09:17:48.406412841Z",
     "start_time": "2023-09-30T09:17:48.179384160Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from Code.DataProcessing.NameDataSet import NameDataSet\n",
    "from Code.utils.set_seed import set_seed\n",
    "from Code.utils.torch_utils import calculate_loss_on_batch, calculate_loss_on_data_loader,generate_new_word_from_torch_model\n",
    "\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T09:17:48.736604297Z",
     "start_time": "2023-09-30T09:17:48.729824944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2131\n"
     ]
    }
   ],
   "source": [
    "seed = 2131\n",
    "padding = 3\n",
    "file_name = './Data/Processed/names.txt'\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T09:20:36.789224305Z",
     "start_time": "2023-09-30T09:20:36.316078357Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = NameDataSet(file_name, add_padding=padding)\n",
    "\n",
    "input = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T09:17:50.746956725Z",
     "start_time": "2023-09-30T09:17:50.726457549Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(input))\n",
    "valid_size = len(input) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(input, [train_size, valid_size])\n",
    "train_dataset = t.Tensor(train_dataset).type(t.LongTensor)\n",
    "valid_dataset = t.Tensor(valid_dataset).type(t.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_characters = len(data.characters)\n",
    "embedding_dim = 2\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(number_of_characters, embedding_dim),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(padding*embedding_dim,hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, number_of_characters)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "lr = .01\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 2.0516269207000732 | valid : 2.065709114074707\n",
      "train : 1.9764305353164673 | valid : 2.001750946044922\n",
      "train : 1.9401575326919556 | valid : 1.9749449491500854\n",
      "train : 1.9176167249679565 | valid : 1.958815336227417\n",
      "train : 1.8958930969238281 | valid : 1.9414628744125366\n",
      "train : 1.8882064819335938 | valid : 1.9414864778518677\n",
      "train : 1.873475193977356 | valid : 1.919724702835083\n",
      "train : 1.8728091716766357 | valid : 1.922545313835144\n",
      "train : 1.8566153049468994 | valid : 1.9142165184020996\n",
      "train : 1.8489621877670288 | valid : 1.9109246730804443\n",
      "train : 1.8404197692871094 | valid : 1.9027405977249146\n",
      "train : 1.8375804424285889 | valid : 1.9078409671783447\n",
      "train : 1.8273080587387085 | valid : 1.8954378366470337\n",
      "train : 1.825286626815796 | valid : 1.8980555534362793\n",
      "train : 1.8208345174789429 | valid : 1.8972927331924438\n",
      "train : 1.8163747787475586 | valid : 1.895886778831482\n",
      "train : 1.8100426197052002 | valid : 1.8873236179351807\n",
      "train : 1.8015775680541992 | valid : 1.8838926553726196\n",
      "train : 1.7940019369125366 | valid : 1.873145341873169\n",
      "train : 1.7991927862167358 | valid : 1.88131844997406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    epoch_train_loss = []\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for batch in train_loader:\n",
    "        loss = calculate_loss_on_batch(model, batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with t.no_grad():\n",
    "        valid_loss = calculate_loss_on_data_loader(model, valid_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "    \n",
    "        train_loss = calculate_loss_on_data_loader(model, train_loader)\n",
    "        train_loss_list.append(train_loss)\n",
    "    \n",
    "    print(f'train : {train_loss_list[-1]} | valid : {valid_loss_list[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "صاج\n",
      "محمدباسن\n",
      "دیتی\n",
      "ژین\n",
      "مان\n",
      "سرین\n",
      "سبر\n",
      "رمحمدام\n",
      "امین\n",
      "سمیفبامیرشارل\n",
      "جرپین\n",
      "شور\n",
      "تهپاسس\n",
      "مهله\n",
      "دلسحس\n",
      "فوعیی\n",
      "ماکبان\n",
      "مالس\n",
      "آنل\n",
      "میدامه\n",
      "شعیاق\n",
      "دجا\n",
      "عهاس\n",
      "محمدالرکالی\n",
      "ماهپرسآفرا\n",
      "رریر\n",
      "محن\n",
      "فبالبه\n",
      "گلیام\n",
      "اعالفرنین\n",
      "سنهنسب\n",
      "صهرا\n",
      "گهیدین\n",
      "محمدعام\n",
      "ذارا\n",
      "خواهن\n",
      "نهشر\n",
      "مسمضاا\n",
      "گلین\n",
      "سضدفلان\n",
      "جایم\n",
      "عیه\n",
      "مهراندش\n",
      "محمدخت\n",
      "اشو\n",
      "اندخت\n",
      "سوز\n",
      "بایش\n",
      "کاین\n",
      "نگز\n",
      "سوفخن\n",
      "پربی\n",
      "برفم\n",
      "کوسحا\n",
      "حسه\n",
      "آلز\n",
      "مهران\n",
      "اهپاعان\n",
      "پریددیر\n",
      "بفیسمساس\n",
      "معاحدیبهتاد\n",
      "محمدمدریسمهرمند\n",
      "فید\n",
      "گلان\n",
      "شرواد\n",
      "فهد\n",
      "مهساو\n",
      "بور\n",
      "روشموعه\n",
      "گلس\n",
      "شما\n",
      "گلفئر\n",
      "لریسبادد\n",
      "نثسری\n",
      "میسبسانو\n",
      "رهن\n",
      "گلاه\n",
      "حمچدا\n",
      "گرمید\n",
      "میمسلب\n",
      "مدروان\n",
      "دلیرا\n",
      "نازلهرال\n",
      "زودالل\n",
      "بهر\n",
      "پنا\n",
      "امرهلاتا\n",
      "نتوتالی\n",
      "پار\n",
      "شفر\n",
      "کدریا\n",
      "گلور\n",
      "صرالمه\n",
      "لوا\n",
      "بهار\n",
      "یمان\n",
      "ژوروا\n",
      "گلسهرهادارامارحتاا\n",
      "پانه\n",
      "گلآلانل\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print(generate_new_word_from_torch_model(model, data.start_character, data.end_character, data.padding, data.ctoi, data.itoc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
